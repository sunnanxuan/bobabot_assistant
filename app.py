# -*- coding: utf-8 -*-
"""
app.py â€” Streamlit å‰ç«¯ï¼ˆå¯¹è¯ç‚¹å• + ç¡®è®¤æäº¤ï¼‰
ä¾èµ–ï¼š
  pip install streamlit langchain langchain-openai python-dotenv requests tiktoken

ç¯å¢ƒå˜é‡ï¼ˆ.envï¼‰ï¼š
  OPENAI_API_KEY=sk-xxxx
  FT_MODEL=ft:gpt-4o-mini-2024-07-18:personal::YOUR_ID
  MODEL_TEMP=0.3
  BOT_NAME=BobaBot
  BACKEND_URL=http://localhost:8000
  BACKEND_TOKEN=change-this-to-a-long-random-secret
"""

import os
import json
import uuid
import requests
import streamlit as st
from dotenv import load_dotenv

from langchain_openai import ChatOpenAI
from langchain_core.messages import SystemMessage, HumanMessage, AIMessage, ToolMessage

from prompts import get_system_prompt
from tools import TOOLS, quote_price, list_menu, can_make_hot

# ========== è¯»å– .env ==========
load_dotenv()
FT_MODEL = os.getenv("FT_MODEL") or os.getenv("BASE_FALLBACK_MODEL", "gpt-4o-mini-2024-07-18")
MODEL_TEMP = float(os.getenv("MODEL_TEMP", "0.3"))
BOT_NAME = os.getenv("BOT_NAME", "BobaBot")
BACKEND_URL = os.getenv("BACKEND_URL", "http://localhost:8000")
BACKEND_TOKEN = os.getenv("BACKEND_TOKEN", "devtoken")

# ========== æ¨¡å‹ä¸æç¤ºè¯ ==========
SYSTEM_PROMPT = get_system_prompt(BOT_NAME)
llm = ChatOpenAI(model=FT_MODEL, temperature=MODEL_TEMP)
llm_with_tools = llm.bind_tools(TOOLS)

# ========== Streamlit UI ==========
st.set_page_config(page_title=f"{BOT_NAME} Â· å¥¶èŒ¶åº—å‘˜", layout="centered")
st.title(f"ğŸ§‹ {BOT_NAME} Â· å¥¶èŒ¶åº—å‘˜")

# å¯¹è¯ä¸è´­ç‰©è½¦çŠ¶æ€
if "msgs" not in st.session_state:
    st.session_state.msgs = [SystemMessage(content=SYSTEM_PROMPT)]
if "cart" not in st.session_state:
    st.session_state.cart = []              # å·²ç¡®è®¤åŠ å…¥è®¢å•çš„æ¯å­
if "pending_item" not in st.session_state:
    st.session_state.pending_item = None    # æœ€è¿‘ä¸€æ¬¡æŠ¥ä»·ï¼ˆå¾…ç¡®è®¤ï¼‰

# å±•ç¤ºå†å²æ¶ˆæ¯
for m in st.session_state.msgs:
    if isinstance(m, HumanMessage):
        st.chat_message("user").write(m.content)
    elif isinstance(m, AIMessage):
        st.chat_message("assistant").write(m.content)

# ä¾§æ è´­ç‰©è½¦
with st.sidebar:
    st.subheader("ğŸ›’ å½“å‰è®¢å•")
    if st.session_state.pending_item:
        pi = st.session_state.pending_item
        st.write(f"å¾…ç¡®è®¤ï¼š{pi['drink']} {pi['size']} - Â¥{pi['total']}")
    if st.session_state.cart:
        for i, it in enumerate(st.session_state.cart, 1):
            st.write(f"{i}. {it['drink']} {it['size']} - Â¥{it['total']}")
    st.write("---")
    st.write("åˆè®¡ï¼šÂ¥", sum(x["total"] for x in st.session_state.cart))

# ===== æäº¤è®¢å•åˆ° FastAPI åç«¯ =====
def submit_order_to_backend(items: list):
    total = sum(x["total"] for x in items)
    payload = {
        "items": [
            {
                "drink": x["drink"],
                "size": x["size"],
                "hot": bool(x.get("hot")),
                "sugar": x.get("sugar"),
                "ice": x.get("ice"),
                "extras": [e["name"] for e in x.get("extras", [])],
                "base_price": x.get("base_price", 0),
                "extras_cost": sum(e["price"] for e in x.get("extras", [])),
                "line_total": x["total"],
            }
            for x in items
        ],
        "total": total,
        "channel": "streamlit",
        "client_order_id": str(uuid.uuid4()),  # å¹‚ç­‰é”®
    }
    r = requests.post(
        f"{BACKEND_URL}/orders",
        headers={"Authorization": f"Bearer {BACKEND_TOKEN}"},
        json=payload,
        timeout=15,
    )
    r.raise_for_status()
    return r.json()  # {order_id, pickup_code, total, created_at, status}

# ===== å¤„ç†å·¥å…·è°ƒç”¨ =====
def handle_tool_call(tc):
    name, args = tc["name"], (tc.get("args") or {})
    if name == "quote_price":
        result = quote_price.invoke(args)
        # æŠ¥ä»·æˆåŠŸï¼šæŠŠä¸Šä¸€æ¯ï¼ˆå¦‚æœæœ‰ï¼‰å…ˆåŠ å…¥è´­ç‰©è½¦ï¼›å½“å‰ä½œä¸ºå¾…ç¡®è®¤é¡¹
        if result.get("ok"):
            if st.session_state.pending_item:
                st.session_state.cart.append(st.session_state.pending_item)
            st.session_state.pending_item = result
        return result
    elif name == "list_menu":
        return list_menu.invoke(args)
    elif name == "can_make_hot":
        return can_make_hot.invoke(args)
    else:
        return {"ok": False, "error": f"æœªçŸ¥å·¥å…·ï¼š{name}"}

# ===== å•è½®æ‰§è¡Œï¼ˆå·²ä¿®å¤â€œai=null/ä¸æ˜¾ç¤ºæ–‡æœ¬â€ï¼‰ =====
def run_turn(user_text: str):
    # è§¦å‘æäº¤è®¢å•
    if user_text.strip() in {"ç¡®è®¤ç‚¹å•", "ç¡®è®¤ä¸‹å•", "ç¡®è®¤ç‚¹é¤"}:
        items = list(st.session_state.cart)
        if st.session_state.pending_item:
            items.append(st.session_state.pending_item)
            st.session_state.pending_item = None
        if not items:
            st.chat_message("assistant").write("å½“å‰æ²¡æœ‰å·²ç¡®è®¤çš„é¥®å“ï¼Œè¯·å…ˆç‚¹å•å“¦ã€‚")
            return
        try:
            resp = submit_order_to_backend(items)
            st.session_state.cart.clear()
            msg = f"âœ… ä¸‹å•æˆåŠŸï¼å–ä»¶ç ï¼š**{resp['pickup_code']}**ï¼Œåˆè®¡ï¼šÂ¥{resp['total']}ã€‚éœ€è¦æˆ‘å†å¸®ä½ åŠ å•æˆ–ä¿®æ”¹å—ï¼Ÿ"
            st.session_state.msgs.append(AIMessage(content=msg))
            st.chat_message("assistant").write(msg)
        except Exception as e:
            st.session_state.msgs.append(AIMessage(content=f"ä¸‹å•å¤±è´¥ï¼š{e}"))
            st.chat_message("assistant").write(f"ä¸‹å•å¤±è´¥ï¼š{e}")
        return

    # æ™®é€šå¯¹è¯ï¼ˆæ¨¡å‹ + å·¥å…·ï¼‰
    st.session_state.msgs.append(HumanMessage(user_text))
    st.chat_message("user").write(user_text)   # ç«‹åˆ»æ¸²æŸ“å½“å‰ç”¨æˆ·æ¶ˆæ¯

    try:
        ai: AIMessage = llm_with_tools.invoke(st.session_state.msgs)
    except Exception as e:
        st.error(f"è°ƒç”¨æ¨¡å‹å¤±è´¥ï¼š{e}")
        return

    st.session_state.msgs.append(ai)

    # å…¼å®¹ä¸åŒç‰ˆæœ¬çš„ tool_calls å–æ³•
    tool_calls = getattr(ai, "tool_calls", None)
    if not tool_calls and hasattr(ai, "additional_kwargs"):
        tool_calls = ai.additional_kwargs.get("tool_calls")

    if tool_calls:
        # 1) æ‰§è¡Œå·¥å…·å¹¶ç”¨ ToolMessage å›ä¼ 
        for tc in tool_calls:
            result = handle_tool_call(tc)
            st.session_state.msgs.append(
                ToolMessage(content=json.dumps(result, ensure_ascii=False), tool_call_id=tc["id"])
            )

        # 2) å†å–æœ€ç»ˆæ–‡æœ¬ï¼›è‹¥ä»æœ‰å·¥å…·è°ƒç”¨ï¼Œå†è¡¥ 2 è½®
        final: AIMessage = llm_with_tools.invoke(st.session_state.msgs)
        for _ in range(2):
            more_calls = getattr(final, "tool_calls", None)
            if not more_calls and hasattr(final, "additional_kwargs"):
                more_calls = final.additional_kwargs.get("tool_calls")
            if not more_calls:
                break
            for tc in more_calls:
                result = handle_tool_call(tc)
                st.session_state.msgs.append(
                    ToolMessage(content=json.dumps(result, ensure_ascii=False), tool_call_id=tc["id"])
                )
            final = llm_with_tools.invoke(st.session_state.msgs)

        st.session_state.msgs.append(final)
        st.chat_message("assistant").write(final.content or "ï¼ˆå·²å®Œæˆå·¥å…·è°ƒç”¨ï¼‰")
    else:
        # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼šç›´æ¥æ¸²æŸ“æ–‡æœ¬ï¼ˆé¿å… None æ˜¾ç¤ºä¸º nullï¼‰
        st.chat_message("assistant").write(ai.content or "ï¼ˆå·²æ”¶åˆ°ï¼‰")

# ===== è¾“å…¥æ¡† =====
user = st.chat_input("ç‚¹å•/è¯¢ä»·/æ¨è/ä»‹ç»â€¦â€¦ï¼ˆä¸‹å•æ—¶å¯ç›´æ¥è¾“å…¥ï¼šç¡®è®¤ç‚¹å•ï¼‰")
if user:
    run_turn(user)
